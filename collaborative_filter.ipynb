{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "from duckdb.experimental.spark.sql.functions import avg\n",
    "\n",
    "from util.data_loader import DataLoader\n",
    "\n",
    "\n",
    "def pearson_coefficient(u:np.ndarray, v:np.ndarray)->float:\n",
    "    u_diff = u-np.mean(u)\n",
    "    v_diff = v-np.mean(v)\n",
    "    분자 = np.dot(u_diff, v_diff)\n",
    "    분모 = np.sqrt(sum(u_diff**2)) * np.sqrt(sum(v_diff**2))\n",
    "    if 분모==0:\n",
    "        return 0\n",
    "    return 분자/분모\n",
    "\n",
    "# dataset = DataLoader().main()\n",
    "# user_movie_matrix = dataset.train.pivot(index=\"user_id\", columns=\"movie_id\", values='rating')\n",
    "# user_id2index = dict(zip(user_movie_matrix.index, range(len(user_movie_matrix.index))))\n",
    "# movie_id2index = dict(zip(user_movie_matrix.columns, range(len(user_movie_matrix.columns))))\n",
    "# movie_rating_predict = dataset.test.copy()\n",
    "\n",
    "#매트릭스 만들어 , 그리고 매트릭스 인덱스 대응하는 표만들고 테스트 복사한거를 평가 예측에만 사용\n",
    "dataset = DataLoader().main()\n",
    "user_movie_matrix = dataset.train.pivot(index=\"user_id\", columns=\"movie_id\", values=\"rating\")\n",
    "user_id2index = dict(zip(user_movie_matrix.index, range(len(user_movie_matrix.index))))\n",
    "movie_id2index = dict(zip(user_movie_matrix.columns, range(len(user_movie_matrix.columns))))\n",
    "pred_test = dataset.test.copy()\n",
    "pred_love_items = defaultdict(list)\n",
    "test_users = pred_test.user_id.unique()\n",
    "for test_user_id in test_users:\n",
    "    similar_user_id = []\n",
    "    similarity = []\n",
    "    avg = []\n",
    "\n",
    "    for user_id in user_movie_matrix.index:\n",
    "        if user_id == test_user_id:\n",
    "            continue\n",
    "        u1 = user_movie_matrix.loc[test_user_id, :].to_numpy()\n",
    "        u2 = user_movie_matrix.loc[user_id, :].to_numpy()\n",
    "\n",
    "        common_df = (~np.isnan(u1) & ~np.isnan(u2))\n",
    "        if not common_df.any():\n",
    "            continue\n",
    "        u1 = u1[common_df]\n",
    "        u2 = u2[common_df]\n",
    "        상관계수 = pearson_coefficient(u1,u2)\n",
    "        if 상관계수 >0:\n",
    "            similar_user_id.append(user_id)\n",
    "            similarity.append(상관계수)\n",
    "            avg.append(np.mean(u2))\n",
    "    avg_ = np.mean(user_movie_matrix.loc[test_user_id,:].dropna().to_numpy())\n",
    "    test_movies = pred_test[pred_test[\"user_id\"]==test_user_id].movie_id.values\n",
    "\n",
    "    pred_test.loc[(pred_test[\"user_id\"]==test_user_id), \"rating_pred\"]=avg_\n",
    "\n",
    "    if similar_user_id:\n",
    "        for movie_id in test_movies:\n",
    "            r_xy = user_movie_matrix.loc[similar_user_id,movie_id].to_numpy()\n",
    "            rating_exists = ~np.isnan(r_xy)\n",
    "            if not rating_exists.any():\n",
    "                continue\n",
    "            r_xy = r_xy[rating_exists]\n",
    "            rho_1x = np.array(similarity)[rating_exists]\n",
    "            avg_x = np.array(avg)[rating_exists]\n",
    "            r_hat_1y = avg_+np.dot(rho_1x, (r_xy-avg_x))/rho_1x.sum()\n",
    "\n",
    "            pred_test.loc[(pred_test[\"user_id\"]==test_user_id)&(pred_test[\"movie_id\"]==movie_id), \"rating_pred\"]=r_hat_1y\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
